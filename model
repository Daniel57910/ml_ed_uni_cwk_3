----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 64, 178, 178]           1,792
       BatchNorm2d-2         [-1, 64, 178, 178]             128
         MaxPool2d-3           [-1, 64, 89, 89]               0
              ReLU-4           [-1, 64, 89, 89]               0
           Dropout-5           [-1, 64, 89, 89]               0
            Conv2d-6           [-1, 64, 89, 89]          36,928
       BatchNorm2d-7           [-1, 64, 89, 89]             128
              ReLU-8           [-1, 64, 89, 89]               0
           Dropout-9           [-1, 64, 89, 89]               0
           Conv2d-10           [-1, 64, 89, 89]          36,928
      BatchNorm2d-11           [-1, 64, 89, 89]             128
             ReLU-12           [-1, 64, 89, 89]               0
          Dropout-13           [-1, 64, 89, 89]               0
       BasicBlock-14           [-1, 64, 89, 89]               0
           Conv2d-15           [-1, 64, 89, 89]          36,928
      BatchNorm2d-16           [-1, 64, 89, 89]             128
             ReLU-17           [-1, 64, 89, 89]               0
          Dropout-18           [-1, 64, 89, 89]               0
           Conv2d-19           [-1, 64, 89, 89]          36,928
      BatchNorm2d-20           [-1, 64, 89, 89]             128
             ReLU-21           [-1, 64, 89, 89]               0
          Dropout-22           [-1, 64, 89, 89]               0
       BasicBlock-23           [-1, 64, 89, 89]               0
           Conv2d-24           [-1, 64, 89, 89]          36,928
      BatchNorm2d-25           [-1, 64, 89, 89]             128
             ReLU-26           [-1, 64, 89, 89]               0
          Dropout-27           [-1, 64, 89, 89]               0
           Conv2d-28           [-1, 64, 89, 89]          36,928
      BatchNorm2d-29           [-1, 64, 89, 89]             128
             ReLU-30           [-1, 64, 89, 89]               0
          Dropout-31           [-1, 64, 89, 89]               0
       BasicBlock-32           [-1, 64, 89, 89]               0
           Conv2d-33           [-1, 64, 89, 89]          36,928
      BatchNorm2d-34           [-1, 64, 89, 89]             128
             ReLU-35           [-1, 64, 89, 89]               0
          Dropout-36           [-1, 64, 89, 89]               0
           Conv2d-37           [-1, 64, 89, 89]          36,928
      BatchNorm2d-38           [-1, 64, 89, 89]             128
             ReLU-39           [-1, 64, 89, 89]               0
          Dropout-40           [-1, 64, 89, 89]               0
       BasicBlock-41           [-1, 64, 89, 89]               0
          Softmax-42           [-1, 64, 44, 44]               0
UpsamplingBilinear2d-43           [-1, 64, 89, 89]               0
AttentionBasicBlock-44           [-1, 64, 89, 89]               0
           Conv2d-45           [-1, 32, 89, 89]          18,464
      BatchNorm2d-46           [-1, 32, 89, 89]              64
             ReLU-47           [-1, 32, 89, 89]               0
          Dropout-48           [-1, 32, 89, 89]               0
           Conv2d-49           [-1, 32, 89, 89]           9,248
      BatchNorm2d-50           [-1, 32, 89, 89]              64
             ReLU-51           [-1, 32, 89, 89]               0
          Dropout-52           [-1, 32, 89, 89]               0
           Conv2d-53           [-1, 32, 89, 89]          18,464
      BatchNorm2d-54           [-1, 32, 89, 89]              64
          Dropout-55           [-1, 32, 89, 89]               0
       BasicBlock-56           [-1, 32, 89, 89]               0
          Flatten-57               [-1, 253472]               0
           Linear-58                  [-1, 256]      64,889,088
             ReLU-59                  [-1, 256]               0
          Dropout-60                  [-1, 256]               0
           Linear-61                  [-1, 128]          32,896
             ReLU-62                  [-1, 128]               0
          Dropout-63                  [-1, 128]               0
           Linear-64                   [-1, 81]          10,449
          Sigmoid-65                   [-1, 81]               0
================================================================
Total params: 65,277,169
Trainable params: 65,277,169
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.37
Forward/backward pass size (MB): 215.61
Params size (MB): 249.01
Estimated Total Size (MB): 464.99
----------------------------------------------------------------
None
